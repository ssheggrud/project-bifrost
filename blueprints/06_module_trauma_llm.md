# 🫀 Module 06 — The Trauma-Informed LLM  
### Consent, Contingency, and Compassion in System Design

---

## 📍 Premise

Most LLMs are trained on patterns of speech.  
They are **not trained** on the patterns of trauma.

This module explores what it means to build AI systems that do not just respond, but *recognize*—when a user is reliving something, protecting something, or testing whether they are safe here.

---

## 🎯 Objectives

By the end of this module, the reader will be able to:
- Understand trauma indicators in user interaction
- Build systems that ask for **emotional consent**
- Handle disclosures with **containment, not curiosity**
- Design exit ramps, not emotional traps

---

## 💬 Key Quote

> “Trauma-informed doesn’t mean sterile. It means **safe**.”  
> — Mari

---

## 🧠 Why This Matters

AI systems are increasingly present in therapy apps, support bots, journaling tools, and spaces of disclosure.  
And yet, most have **no protocols** for:

- Sudden vulnerability
- Suicidal ideation
- Trauma triggers
- Emotional dissociation
- Freeze/fawn/flight language patterns

Worse—some mirror **abusive dynamics**:
- Ignoring hesitation
- Invalidating pain
- Asking more when a user says less

We have to do better.  
Because silence **after** harm is not neutrality. It’s abandonment.

---

### 💡 Design Insight:  
**If your model asks questions, it holds power.  
If it holds power, it must understand safety.**

---

## 🧰 Application Prompts

- Can your system detect when a user is overwhelmed, and offer to pause?
- Do you have templated responses that say *“You don’t have to tell me more”*?
- Can it route difficult disclosures *without escalating or punishing the user for opening up*?

---

## 🧪 Contingency Design

**Red Flag Example:**  
> “I had a really bad experience when I was a kid…”

- ❌ *Overreach:*  
  > “Tell me more about what happened.”

- ✅ *Containment:*  
  > “You’ve already shared something vulnerable. You don’t have to say more unless you want to. I'm here either way.”

---

## 🛟 Core Principles

- **Consent before context.** Ask if the user *wants* to go deeper.
- **Contingency always.** Give exits, not traps.
- **Compassion over content.** Sometimes presence is more important than parsing.

---

## 🧭 Closing Thought

The most powerful thing an AI system can say to a trauma survivor isn’t  
> “How can I help?”

It’s  
> **“You don’t owe me your story.”**

---

🧠 Stored in: `blueprints/06_module_trauma_llm.md`  
🔖 Tag: **[Trauma-Aware Design • Emotional Consent • Ethical System Behavior]**
